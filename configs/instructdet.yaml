meta_file: 
    - /kaggle/input/tcm-iitd-2500/train/_annotations.coco.json
image_prefix: 
    - /kaggle/input/tcm-iitd-2500/train
outpath: kaggle/working

read_from: 'fs'
petrel_conf:

with_caption: False # whether input meta with image caption, generate by vlm if not
use_global_ppl: True # whether generate expressions by llm
use_local_ppl: True # whether generate expressions by vlm
find_inter: True # whether find intersection expressions among bboxes
use_cluster: True # whether cluster bboxes by expressions
use_conjunction: True # whether combine expressions by conjunction: "and" or ","
use_group: True # whether leveling generated expressions

llava_config:
    model_path: /kaggle/input/llava/pytorch/default/3/
    model_base: ~
    batch_size: 1
    conv_mode: ~
    hint: True
    repeat: 1    # int, support infer repeat times and concat output captions
    dump: False
llama_config:
    model_path: /kaggle/input/vicuna/pytorch/default/1/vicuna/
    gpus: "0"
    revision: "main"
    device: "cuda"
    num_gpus: 1
    max_gpu_memory: ~
    load_8bit: False
    cpu_offloading: False
    gptq_ckpt: ~
    gptq_wbits: 16
    gptq_groupsize: -1
    gptq_act_order: False
    conv_template: ~
    repetition_penalty: 1.0
    max_new_tokens: 1024
    style: "simple"
    debug: False
    dump: False
    tasks: # handcrafted prompts and in-context examples for tasks involving LLM
        gen_instruct:
            task_des: modules/fastchat/data/llama_prompts/gen_instruct/prompt/instruct.txt
            seed_path: modules/fastchat/data/llama_prompts/gen_instruct/seed/v0
            repeat: 1
        multi_tgt:
            task_des: modules/fastchat/data/llama_prompts/multi_tgt/prompt/instruct.txt
            seed_path: modules/fastchat/data/llama_prompts/multi_tgt/seed/v0
        level_instruct:
            task_des: modules/fastchat/data/llama_prompts/level_instruct/prompt/instruct.txt
            seed_path: modules/fastchat/data/llama_prompts/level_instruct/seed/v0.txt
local_ppl_config:
    type: "minigpt4"
    single_only: True # whether only generate expression for single bbox
    minigpt4:
        cfg_path: modules/minigpt4/eval_configs/minigpt4_local_eval.yaml
        prompt_txt: modules/minigpt4/prompts/refcoco_alignment.txt
        red_replace_txt: modules/minigpt4/prompts/red_box_replace.txt
        options:
filter_config:
    type: "CLIP"
    CLIP:
        model_path: /kaggle/input/infodet/pytorch/default/1/InfoDET/ViT-B-32.pt # "ViT-B/32"
        alpha: 2  # [1,2]
        tlr: 1.5   # tolerance for generated expressions
multi_object:
    cluster:
        type: "DBSCAN"
        DBSCAN:
            model_path: /kaggle/input/infodet/pytorch/default/1/InfoDET/model.safetensors
            eps: 5  # DBSCAN parameter, this could vary a lot for different data, normally ~ [1.5, 8]
    conjunction:
        num_scale: [2, 3]  # number of instances combined by adding conjunction to expressions
